# -*- coding: utf-8 -*-
"""DL Project-Plant Disease Classfier(CNN)-Image Classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rFSA_5QJeZbuEvJjy6I7p8XH0SpYf7Yj
"""

#Set Seeds For Reproducibilty
import random
random.seed(0)
import numpy as np
np.random.seed(0)
import tensorflow as tf
tf.random.set_seed(0)

"""**Importing Dependencies**"""

import os
import json
from zipfile import ZipFile
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models

"""**Data Curation**"""

!pip install kaggle

kaggle_credentials=json.load(open("/content/kaggle.json"))
kaggle_credentials

#set up Kaggle API key as environment variables
os.environ['KAGGLE_USERNAME']=kaggle_credentials['username']
os.environ['KAGGLE_KEY']=kaggle_credentials['key']

!kaggle datasets download -d abdallahalidev/plantvillage-dataset

!ls

#unzip the downloaded the dataset
with ZipFile('/content/plantvillage-dataset.zip','r') as zip_ref:
  zip_ref.extractall()

print(os.listdir('/content/plantvillage dataset/'))

print(len(os.listdir('/content/plantvillage dataset/segmented')))

print(os.listdir('/content/plantvillage dataset/segmented')[:5])

print(len(os.listdir('/content/plantvillage dataset/color')))

print(os.listdir('/content/plantvillage dataset/color')[:5])

print(len(os.listdir('/content/plantvillage dataset/grayscale')))

print(os.listdir('/content/plantvillage dataset/grayscale')[:5])

print(len(os.listdir('/content/plantvillage dataset/color/Grape___healthy')))
print(os.listdir('/content/plantvillage dataset/color/Grape___healthy')[:5])

"""**Data Preprocessing**"""

#Dataset path
basedir='/content/plantvillage dataset/color'

image_path='/content/plantvillage dataset/color/Apple___Cedar_apple_rust/04da297e-5238-41b1-a8a0-0c87c6c2f21f___FREC_C.Rust 4394.JPG'
img=mpimg.imread(image_path)
print(img.shape)
plt.imshow(img)
plt.axis('off')#turn off axis numbers
plt.show()

#Image Paramaeters
img_size=224
batch_size=32

#Image Data Generators
data_gen=ImageDataGenerator(
    rescale=1./255,validation_split=0.2
)#use 20% of the data
data_gen

"""**Train Test Split**"""

#Train Generator
train_generator=data_gen.flow_from_directory(
    basedir,
    target_size=(img_size,img_size),
    batch_size=batch_size,
    subset='training',
    class_mode='categorical'
)

#Validation Generator
validation_generator=data_gen.flow_from_directory(
    basedir,
    target_size=(img_size,img_size),
    batch_size=batch_size,
    subset='validation',
    class_mode='categorical'
)

"""**Convulational Neural Network**"""

model=models.Sequential()
model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(img_size,img_size,3)))
model.add(layers.MaxPooling2D((2,2)))

model.add(layers.Conv2D(64,(3,3),activation='relu'))
model.add(layers.MaxPooling2D((2,2)))

model.add(layers.Flatten())
model.add(layers.Dense(256,activation='relu'))
model.add(layers.Dense(train_generator.num_classes,activation='softmax'))

model.summary()

#Compile The Model
model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])

"""**Model Training**"""

history=model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples//batch_size,
    epochs=5,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples//batch_size
)

"""**Model Evaluation**"""

print("Evaluation Results")
val_loss,val_accuracy=model.evaluate(validation_generator,steps=validation_generator.samples//batch_size)

print(f"Validation Accuracy: {val_accuracy*100:.2f}%")

#Ploting Training and Validation Accuracy Values
plt.plot(history.history['accuracy'],label='Training Accuracy')
plt.plot(history.history['val_accuracy'],label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(['Train','Test'],loc='upper left')
plt.show()

#Plot Training and Validation Loss Values
plt.plot(history.history['loss'],label='Training Loss')
plt.plot(history.history['val_loss'],label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend(['Train','Test'],loc='upper left')
plt.show()

"""**Building a Predictive System**"""

#Function to load and preprocess the image using pillow
def load_and_preprocess_image(image_path,target_size=(224,224)):
  #load the image
  img=Image.open(image_path)
  #resize the image
  img=img.resize(target_size)
  #convert the image to a numpy array
  img_array=np.array(img)
  #add batch dimension
  img_array=np.expand_dims(img_array,axis=0)
  #scale the image values to (0,1)
  img_array=img_array.astype('float32')/255.0
  return img_array

#Fucntion to predict the class of the image
def predict_image_class(model,image_path,class_indices):
  #load and preprocess the image
  preprocessed_img=load_and_preprocess_image(image_path)
  #make predictions
  predictions=model.predict(preprocessed_img)
  predicted_class_index=np.argmax(predictions)
  #map the predicted class index to the corresponding class label
  #predicted_class_label=list(class_indices.keys())[list(class_indices.values()).index(predicted_class_index)]
  predicted_class_name=class_indices[predicted_class_index]
  return predicted_class_name

#Create a mapping from class indices to class names
class_indices={v:k for k,v in train_generator.class_indices.items()}
class_indices

#Saving the class name as json file
json.dump(class_indices,open("class_indices.json","w"))

#example
image_path="/strawberry_leaf_scorch.jpg"
predicted_class_name=predict_image_class(model,image_path,class_indices)

#Output Result
print(f"The predicted class is: {predicted_class_name}")

from google.colab import drive
drive.mount('/content/drive.h5')